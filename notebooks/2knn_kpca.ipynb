{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is taught to show a KNN algorithm, coupled with a KNN for benchmarking purposes to the other models deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sources:\n",
    "txpath = 'toxicity_labels.csv'\n",
    "data = 'data.csv'\n",
    "un = 'unknown_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#method specific imports\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing\n",
    "\n",
    "#labels\n",
    "y_id = []\n",
    "y = []\n",
    "file = open(txpath, \"r\")\n",
    "for line in file:\n",
    "    ys = line.strip().split(\",\")\n",
    "    y_id.append(ys[0])\n",
    "    y.append(ys[1].replace('NA', '2'))\n",
    "file.close()\n",
    "#data\n",
    "X_id = []\n",
    "X = []\n",
    "file = open(data, \"r\")\n",
    "for line in file:\n",
    "    ys = line.strip().split(\",\")\n",
    "    X_id.append(ys[0])\n",
    "    X.append(ys[1:])\n",
    "file.close() \n",
    "#unknown data\n",
    "Xu_id = []\n",
    "Xu = []\n",
    "file = open(un, \"r\")\n",
    "for line in file:\n",
    "    ys = line.strip().split(\",\")\n",
    "    Xu_id.append(ys[0])\n",
    "    Xu.append(ys[1:])    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion of lists to numpy arrays and re-definition of data types\n",
    "y_id = np.array(y_id[1:])\n",
    "X_id = np.array(X_id[1:])\n",
    "Xu_id = np.array(Xu_id[1:])\n",
    "y_head = np.array(y[0])\n",
    "X_head = np.array(X[0])\n",
    "\n",
    "#re-definition of data types\n",
    "X = np.array(X[1:], dtype='float64')\n",
    "Xu = np.array(Xu[1:], dtype='float64')\n",
    "y = np.array(y[1:], dtype='i1')  # int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "#cleaning of data with missing labels\n",
    "#(Number of values with missing label NA: 3619)\n",
    "rm = np.where(y == 2)\n",
    "X = np.delete(X, rm[0], axis=0)\n",
    "X_id = np.delete(X_id, rm[0])\n",
    "y = np.delete(y, rm[0])\n",
    "y_id = np.delete(y_id, rm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "#normalization (zero-score method)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Xu = scaler.transform(Xu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: KPCA with KNN, optimized on the amount of neighbors\n",
    "\n",
    "steps:\n",
    "KPCA with a linear kernel\n",
    "Cross validation (CV) wrapped around a train test split of 80/20\n",
    "KNN: finding best amount of neighbors\n",
    "Retrain KNN on with the best amount of neighbors\n",
    "Calculation of metrices for model selection\n",
    "data export to .csv file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#KPCA\n",
    "\n",
    "pca = KernelPCA(n_components=80, kernel='linear',fit_inverse_transform=True, alpha=1)\n",
    "Xr=pca.fit_transform(X)\n",
    "Xur=pca.transform(Xu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "#lists to store metrices\n",
    "best_acc_val = []\n",
    "best_acc_test = []\n",
    "best_neighbors = []\n",
    "best_pre_test = []\n",
    "best_mcc_test = []\n",
    "best_auc_test = []\n",
    "recall_values = []\n",
    "\n",
    "#Perform cross validation and train test split\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(Xr,y):\n",
    "    X_train = Xr[train_index]\n",
    "    X_test = Xr[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "    acc_train = [] \n",
    "    acc_val = []\n",
    "    \n",
    "    X_subtrain, X_val, y_subtrain, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "    neighbors = np.arange(1, 25)\n",
    "    \n",
    "    #Perform line search to find best k\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k,algorithm='ball_tree', weights='distance', metric=\"minkowski\",p=2, n_jobs=-1)\n",
    "        knn.fit(X_subtrain, y_subtrain) \n",
    "        predictions_training = knn.predict(X_subtrain) \n",
    "        predictions_testing = knn.predict(X_val) \n",
    "    \n",
    "        #Store Accuracy\n",
    "        acc_train.append(metrics.matthews_corrcoef(y_subtrain,predictions_training))\n",
    "        acc_val.append(metrics.matthews_corrcoef(y_val,predictions_testing))\n",
    "    \n",
    "    #Store best neighbor information\n",
    "    best_k = neighbors[np.argmax(acc_val)]\n",
    "    best_neighbors.append(best_k)\n",
    "    best_acc_val.append(acc_val[np.argmax(acc_val)])\n",
    "    \n",
    "    #retrain Model with best k and predict it on test data\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, algorithm='ball_tree', weights='distance',metric=\"minkowski\",p=2, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train) \n",
    "    y_prediction = knn.predict(X_test)\n",
    "    \n",
    "    best_acc_test.append(metrics.accuracy_score(y_test,y_prediction))\n",
    "    best_pre_test.append(metrics.precision_score(y_test,y_prediction))\n",
    "    best_mcc_test.append(metrics.matthews_corrcoef(y_test,y_prediction))\n",
    "    best_auc_test.append(metrics.roc_auc_score(y_test,y_prediction))\n",
    "    recall_values.append(metrics.recall_score(y_test,y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average k: 5.00 (+- 4.00)\n",
      "Average Acc (Val): 0.50 (+- 0.04)\n",
      "Average Acc (Test): 0.89 (+- 0.01)\n",
      "Average pre (Test): 0.54 (+- 0.04)\n",
      "Average mcc (Test): 0.40 (+- 0.03)\n",
      "AUC:\t0.67 (+-0.01)\n",
      "Recall:\t\t0.39 (+-0.01)\n"
     ]
    }
   ],
   "source": [
    "#data processing and metrics calculation\n",
    "\n",
    "#transform python list into numpy array\n",
    "best_neighbors = np.array(best_neighbors)\n",
    "best_acc_val = np.array(best_acc_val)\n",
    "best_acc_test = np.array(best_acc_test)\n",
    "best_pre_test = np.array(best_pre_test)\n",
    "best_mcc_test = np.array(best_mcc_test)\n",
    "best_auc_test = np.array(best_auc_test)\n",
    "recall_values = np.array(recall_values)\n",
    "\n",
    "#print metrics\n",
    "print(\"Average k: %.2f (+- %.2f)\" % (best_neighbors.mean(),best_neighbors.std()))\n",
    "print(\"Average Acc (Val): %.2f (+- %.2f)\" % (best_acc_val.mean(),best_acc_val.std()))\n",
    "print(\"Average Acc (Test): %.2f (+- %.2f)\" % (best_acc_test.mean(),best_acc_test.std()))\n",
    "print(\"Average pre (Test): %.2f (+- %.2f)\" % (best_pre_test.mean(),best_pre_test.std()))\n",
    "print(\"Average mcc (Test): %.2f (+- %.2f)\" % (best_mcc_test.mean(),best_mcc_test.std()))\n",
    "print(\"AUC:\\t%.2f (+-%.2f)\" % (np.mean(best_auc_test), np.std(best_auc_test)))\n",
    "print(\"Recall:\\t\\t%.2f (+-%.2f)\" % (np.mean(recall_values),np.std(recall_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of toxic labels of unknown data set 64\n",
      "Number of non-toxic labels of unknown data set 546\n"
     ]
    }
   ],
   "source": [
    "#export format for leaderboard submission\n",
    "\n",
    "un_pred = knn.predict(Xur)\n",
    "un_pred = np.array(un_pred)\n",
    "exp = np.column_stack((Xu_id, un_pred))\n",
    "np.savetxt('exp_kpca_knn.csv',exp, delimiter=',', fmt=\"%s\")\n",
    "\n",
    "print('Number of toxic labels of unknown data set %d' % np.sum(un_pred == 1))\n",
    "print('Number of non-toxic labels of unknown data set %d' %np.sum(un_pred == 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
